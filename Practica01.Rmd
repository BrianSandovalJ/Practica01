---
title: "Practica 1"
author: "Brian Sandoval"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(tidyverse)
library(htmlTable)
library(lubridate)
library(ggplot2)
library(mltools)
library(data.table)
library(mltools)

#epa_http <- read_table("C:/Users/briansj/Documents/Trabajo01/epa-http.csv", col_names = FALSE)
epa_http <- read_table("~/Downloads/Practica01-main/epa-http.csv", col_names = FALSE)
colnames(epa_http) <- c("Origen","Tiempo","Tipo Peticion", "URL", "Version","Respuesta","Bytes")
epa_http_one_hot <- one_hot(as.data.table(epa_http), sparsifyNAs = TRUE)
#View(epa_http)

```

## Practica 01 - Data Science

***Pregunta 01:***

1.- Dado un registro de vehículos que circulan por una autopista, disponemos de su marca y modelo, país de matriculación, y tipo de vehículo (por número de ruedas). Con tal de ajustar precios de los peajes, ¿Cuántos vehículos tenemos por tipo? ¿Cuál es el tipo más frecuente? ¿De qué países tenemos más vehículos?

La clasificación de la pregunta es predictiva, puesto que, de una data de frecuencia de vehículos, se puede predecir los tipos de valores nuevos que usan las personas y de igual forma es clasificada descriptiva por que se desea saber el número de países recurrentes que circulan en la autopista.

2.- Dado un registro de visualizaciones de un servicio de video-on-demand, donde disponemos de los datos del usuario, de la película seleccionada, fecha de visualización y categoría de la película, queremos saber ¿Hay alguna preferencia en cuanto a género literario según los usuarios y su rango de edad?

La clasificación de la pregunta es exploratoria, puesto que se esta preguntando sobre la preferencia del genero de los usuarios. Ello conlleva en explorar dentro de la base de datos sobre el gusto de los usuarios.

3.- Dado un registro de peticiones a un sitio web, vemos que las peticiones que provienen de una red de telefonía concreta acostumbran a ser incorrectas y provocarnos errores de servicio. ¿Podemos determina si en el futuro, los próximos mensajes de esa red seguirán dando problemas? ¿Hemos notado el mismo efecto en otras redes de telefonía?

La clasificación de la pregunta es casuales, porque se requiere ver los resultados de los mensajes futuros en caso sigan dando problemas o no. De igual forma es exploratoria porque se requiere investigar si existe relación con otras redes de telefonía.

4.- Dado los registros de usuarios de un servicio de compras por internet, los usuarios pueden agruparse por preferencias de productos comprados. Queremos saber si ¿Es posible que, dado un usuario al azar y según su historial, pueda ser directamente asignado a un o diversos grupos?

La clasificación de la pregunta es predictiva, por que de acuerdo a los datos obtenidos se requiere revisar si puede ser asignado a uno o diversos grupos de acuerdo al historial de productos comprados.

**Pregunta 02:**

Considera el siguiente escenario: Sabemos que un usuario de nuestra red empresarial ha estado usando esta para fines no relacionados con el trabajo, como por ejemplo tener un servicio web no autorizado abierto a la red (otros usuarios tienen servicios web activados y autorizados). No queremos tener que rastrear los puertos de cada PC, y sabemos que la actividad puede haber cesado. Pero podemos acceder a los registros de conexiones TCP de cada máquina de cada trabajador (hacia donde abre conexión un PC concreto). Sabemos que nuestros clientes se conectan desde lugares remotos de forma legítima, como parte de nuestro negocio, y que un trabajador puede haber habilitado temporalmente servicios de prueba. Nuestro objetivo es reducir lo posible la lista de posibles culpables, con tal de explicarles que por favor no expongan nuestros sistemas sin permiso de los operadores o la dirección.

Explica con detalle cómo se podría proceder al análisis y resolución del problema mediante Data Science, indicando de donde se obtendrían los datos, qué tratamiento deberían recibir, qué preguntas hacerse para resolver el problema, qué datos y gráficos se obtendrían, y cómo se comunicarían estos.

En la información guardada debe de estar en un identificador único, nombre completo, apellidos, número de teléfono y correo, nacionalidad y su número de identificación. Teniendo esos datos básicos se puede crear un usuario y contraseña mediante el AD hacia los servicios de Internet asociados en la red empresarial, con ello se sabe mediante el registro asociado sobre la IP, puerto, contraseña, hora y fecha y el usuario que realiza esta comunicación. Se analiza mediante el registro de comunicación que realiza a qué sitio web y a dirección que usa. Teniendo esos usuarios, se realiza un protocolo de roles para identificar los permisos que se brinda y ejecuta dado poco a poco brindado.


------------------------------------------------------------------------

------------------------------------------------------------------------

**Introducción a R**

**Pregunta 1:** Una vez cargado el Dataset a analizar, comprobando que se cargan las IPs, el Timestamp, la Petición (Tipo, URL y Protocolo), Código de respuesta, y Bytes de reply.

1\. Cuales son las dimensiones del dataset cargado (número de filas y columnas)

RSPT: El data frame tiene `r nrow(epa_http)` filas y `r ncol(epa_http)` columnas

2\. Valor medio de la columna Bytes

RSPT: El valor medio es: `r 
tabla_flot <- epa_http
colnames(tabla_flot) <- c("Origen","Tiempo","Tipo Peticion", "URL", "Version","Respuesta","Bytes")
bytes<- as.numeric(tabla_flot$Bytes)
bytes[is.na(bytes)] <- 0
total_bytes <- mean(bytes)
total_bytes`.

**Pregunta 2:** De las diferentes IPs de origen accediendo al servidor, ¿cuantas pertenecen a una IP claramente educativa (que contenga ".edu")? RSPT: Se tiene un total de: `r 
url_edu <- epa_http[grepl(".edu", epa_http$Origen, ignore.case = FALSE), ]
numero_edu <- nrow(url_edu)
numero_edu` IPs.

**Pregunta 3:** De todas las peticiones recibidas por el servidor cual es la hora en la que hay mayor volumen de peticiones HTTP de tipo "GET"? RSPT: El mayor volumen es `r 
tablaflot3 <- epa_http
colnames(tablaflot3) <- c("Origen","Tiempo","Peti", "URL", "Version","Respuesta","Bytes")
totalGET <- tablaflot3[grepl("GET", tablaflot3$Peti, ignore.case = FALSE), ]
dia_hora <- substr(totalGET$Tiempo,5,6)
tabla_dia <- table(dia_hora)
tabla_ordenada <- sort(tabla_dia, decreasing = TRUE)
indice_max <- which.max(tabla_ordenada)
hora_max <- names(tabla_ordenada)[indice_max]
hora_max
` hrs.

**Pregunta 4:** De las peticiones hechas por instituciones educativas (.edu), ¿Cuantos bytes en total se han transmitido, en peticiones de descarga de ficheros de texto ".txt"?

RSPT: El total de bytes es `r 
tablaflot2 <- epa_http 
url_edu <- tablaflot2[grepl(".edu$", tablaflot2$Origen, ignore.case = FALSE), ] 
descargas_txt <-url_edu[grepl(".txt$", url_edu$URL, ignore.case = FALSE), ] 
bytes<- as.numeric(descargas_txt$Bytes) 
bytes[is.na(bytes)] 
suma <- mean(bytes) 
numero_sum <- sum(suma) 
numero_sum`.

**Pregunta 5:** Si separamos la petición en 3 partes (Tipo, URL, Protocolo), usando str_split y el separador " " (espacio), ¿cuantas peticiones buscan directamente la URL = "/"?

RSPT: Buscan directamente `r 
url_5 <- epa_http[grepl("^/$", epa_http$URL, ignore.case = FALSE), ]
numero_total5 <- nrow(url_5)
numero_total5
` URLs.

**Pregunta 6:** Aprovechando que hemos separado la petición en 3 partes (Tipo, URL, Protocolo) ¿Cuantas peticiones NO tienen como protocolo "HTTP/0.2"?

RSPT: Son en total `r 
url_http <- epa_http[!grepl("HTTP/0.2", epa_http$Version, ignore.case = FALSE), ]
numero_totalhttp <- nrow(url_http)
numero_totalhttp
` peticiones.

**Limpieza de los Datos**

1/. Aprovechando que los datos a analizar son los mismos de la primera práctica, para esta entrega es imprescindible que los datos estén en formato de “datos elegantes”.

```{r , echo=T}
tablaFlot4 <- epa_http
colnames(tablaFlot4) <- c("Origen","Tiempo","Peti", "URL", "Version","Respuesta","Bytes")
tablaFlot4$Tiempo <- tablaFlot4$Tiempo %>% str_remove_all("\\[|\\]")
tablaFlot4$Dia <- substr(tablaFlot4$Tiempo, 1, 2)
tablaFlot4$Hora <- substr(tablaFlot4$Tiempo, 4, 11)
tablaFlot4$Bytes <- ifelse(tablaFlot4$Respuesta == 404, 0, tablaFlot4$Bytes)
tablaFlot4$Bytes <- ifelse(tablaFlot4$Respuesta == 302, 1, tablaFlot4$Bytes)
tablaFlot4$Bytes <- ifelse(tablaFlot4$Respuesta == 403, 2, tablaFlot4$Bytes)
tablaFlot4$Bytes <- ifelse(tablaFlot4$Respuesta == 501, 3, tablaFlot4$Bytes)
tablaFlot4$Bytes <- ifelse(tablaFlot4$Respuesta == 400, 4, tablaFlot4$Bytes)
tablaFlot4$Bytes <- as.numeric(tablaFlot4$Bytes)
tablaFlot4$Dia <- as.numeric(tablaFlot4$Dia)
```

2/. Identificar el número único de usuarios que han interactuado directamente con el servidor de forma segregada según si los usuarios han tenido algún tipo de error en las distintas peticiones ofrecidas por el servidor.

```{r , echo=T}
# El codigo 404: indica que la página solicitada por el usuario no se encontró en el servidor
# El codigo 302: indica que una URL específica ha sido trasladada temporalmente a una nueva ubicación
# El codigo 403: indica que el acceso a la página o al dominio solicitado está restringido
# El codigo 501: indica que el servidor no soporta la funcionalidad necesaria para satisfacer la solicitud
# El codigo 400: indica que el servidor no puede o no procesará la solicitud debido a algo que se percibe como un error del cliente
# El codigo 500: indica que algo ha ido mal en el servidor del sitio web
# El codigo 304: indica que la página web que buscaste no ha cambiado desde la última vez que accediste a ella
# El codigo 200: Respuesta exitosa
#unique(tablaFlot4$Respuesta)
#length(unique(tablaFlot4$Respuesta))

frequency_table <- table(tablaFlot4$Respuesta)
frequency_data_frame <- as.data.frame(frequency_table)
names(frequency_data_frame)[1] <- "Valor"
names(frequency_data_frame)[2] <- "Frecuencia"
# Create the bar graph using 'ggplot2'
ggplot(frequency_data_frame, aes(x = Valor, y = Frecuencia)) +
  geom_bar(stat = "identity") +
  labs(title = "Frecuencia observada", x = "Valor", y = "Frecuencia")
```

3/. AnalizarlosdistintostiposdepeticionesHTTP(GET,POST,PUT,DELETE) gestionadas por el servidor, identificando la frecuencia de cada una de estas. Repetir el análisis, esta vez filtrando previamente aquellas peticiones correspondientes a recursos ofrecidos de tipo imagen.

```{r , echo=T}
frequency_table <- table(tablaFlot4$Peti)
frequency_data_frame <- as.data.frame(frequency_table)
names(frequency_data_frame)[1] <- "Valor"
names(frequency_data_frame)[2] <- "Frecuencia"
# Create the bar graph using 'ggplot2'
ggplot(frequency_data_frame, aes(x = Valor, y = Frecuencia)) +
  geom_bar(stat = "identity") +
  labs(title = "Frecuencia observada", x = "Valor", y = "Frecuencia")
```

**Clústering de datos**

1/. Utilizando un algoritmo de aprendizaje no supervisado, realizad un análisis de clústering con k-means para los datos del servidor.

```{r , echo=T}
tablaji <- epa_http_one_hot  # Assuming tablaFlot4 is your data frame


tablaji$Bytes <- ifelse(tablaji$Respuesta == 404, 0, tablaji$Bytes)
tablaji$Bytes <- ifelse(tablaji$Respuesta == 302, 1, tablaji$Bytes)
tablaji$Bytes <- ifelse(tablaji$Respuesta == 403, 2, tablaji$Bytes)
tablaji$Bytes <- ifelse(tablaji$Respuesta == 501, 3, tablaji$Bytes)
tablaji$Bytes <- ifelse(tablaji$Respuesta == 400, 4, tablaji$Bytes)
tablaji$Bytes <- as.numeric(tablaji$Bytes)

tablaji$Peti <- as.factor(tablaji$`Tipo Peticion`)

#tablaji_one_hot <- one_hot(as.data.table(tablaji), sparsifyNAs = TRUE)
#data_onehot <- one_hot(tablaji_one_hot)
data_onehot <- one_hot(as.data.table(tablaji), sparsifyNAs = TRUE)

data_onehot$Origen <- NULL
data_onehot$Tiempo <- NULL
data_onehot$`Tipo Peticion` <- NULL
data_onehot$resourceLenght <- nchar(data_onehot$URL)
data_onehot$URL <- NULL
data_onehot$Version <- NULL

perform_kmeans <- function(k) {
  # Perform k-means clustering using the one-hot encoded data
  kmeans_results <- kmeans(data_onehot[, -1], centers = k)

  # Assign cluster labels to data points
  data_onehot$cluster <- kmeans_results$cluster

  # Print the cluster labels
  #print(data_onehot$cluster)
  ggplot2::ggplot(data_onehot, aes(x = data_onehot$resourceLenght, data_onehot$Bytes, colour = data_onehot$cluster)) +
    geom_point(alpha = 0.2) +
    ggtitle(paste("EPA server logs K-means analysis", k, "cluster"))
}

perform_kmeans(3)
#summary(data_onehot)


```

2/. Representadvisualmenteengráficosdetiposcatterplotelresultadode vuestros clústering y interpretad el resultado obtenido.

```{r , echo=T}

```